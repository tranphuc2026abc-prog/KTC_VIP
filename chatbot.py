import streamlit as st
import os
import glob
import sys

# --- 1. C·∫§U H√åNH TRANG (B·∫ÆT BU·ªòC PH·∫¢I ƒê·ªÇ ƒê·∫¶U TI√äN) ---
st.set_page_config(
    page_title="Chatbot KTC - Tr·ª£ l√Ω Tin h·ªçc",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. KI·ªÇM TRA M√îI TR∆Ø·ªúNG (SAFE MODE) ---
# ƒêo·∫°n n√†y gi√∫p App kh√¥ng b·ªã s·∫≠p ngu·ªìn n·∫øu thi·∫øu th∆∞ vi·ªán
try:
    from groq import Groq
    import pdfplumber
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.vectorstores import FAISS
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_core.documents import Document
    LIBRARIES_OK = True
except ImportError as e:
    LIBRARIES_OK = False
    ERROR_DETAIL = str(e)

# --- 3. GIAO DI·ªÜN B√ÅO L·ªñI (N·∫æU C√ì) ---
if not LIBRARIES_OK:
    st.markdown("<h1 style='text-align: center; color: red;'>‚ö†Ô∏è H·ªÜ TH·ªêNG ƒêANG THI·∫æU TH∆Ø VI·ªÜN</h1>", unsafe_allow_html=True)
    st.error(f"L·ªói c·ª• th·ªÉ: {ERROR_DETAIL}")
    st.warning("üëâ Th·∫ßy Khanh h√£y ki·ªÉm tra l·∫°i file 'requirements.txt' tr√™n Github.")
    st.info(f"Phi√™n b·∫£n Python ƒëang ch·∫°y: {sys.version}")
    st.stop() # D·ª´ng l·∫°i t·∫°i ƒë√¢y, kh√¥ng ch·∫°y ti·∫øp ƒë·ªÉ tr√°nh s·∫≠p app

# =========================================================
# N·∫æU M·ªåI TH·ª® ·ªîN, CODE CH√çNH S·∫º CH·∫†Y T·ª™ ƒê√ÇY
# =========================================================

# --- C√ÅC H·∫∞NG S·ªê ---
MODEL_NAME = 'llama-3.1-8b-instant'
PDF_DIR = "./PDF_KNOWLEDGE"
LOGO_PATH = "LOGO.jpg"
SIMILARITY_THRESHOLD = 1.5 
TOP_K_RETRIEVAL = 6

# --- CSS ---
st.markdown("""
<style>
    .stApp {background-color: #f8f9fa;}
    [data-testid="stSidebar"] {background-color: #ffffff; border-right: 1px solid #e0e0e0;}
    .gradient-text {
        background: linear-gradient(90deg, #0f4c81, #1cb5e0); -webkit-background-clip: text;
        -webkit-text-fill-color: transparent; font-weight: 800; font-size: 2.5rem;
        text-align: center; margin-bottom: 0;
    }
    div[data-testid="stChatMessage"] { background-color: transparent; border: none; padding: 10px; }
    div[data-testid="stChatMessage"][data-testid="user"] { background-color: #e0f2fe; border-radius: 15px 0px 15px 15px; } 
    div[data-testid="stChatMessage"][data-testid="assistant"] { background-color: #ffffff; border: 1px solid #e2e8f0; border-radius: 0px 15px 15px 15px; box-shadow: 0 1px 2px rgba(0,0,0,0.05); }
    .stButton>button { border-radius: 8px; background-color: #0284c7; color: white; border: none; font-weight: 600; }
    .footer-note { text-align: center; font-size: 0.75rem; color: #94a3b8; margin-top: 30px; border-top: 1px dashed #cbd5e1; padding-top: 10px; }
</style>
""", unsafe_allow_html=True)

# --- X·ª¨ L√ù K·∫æT N·ªêI ---
try:
    api_key = st.secrets.get("GROQ_API_KEY", os.getenv("GROQ_API_KEY"))
    if not api_key: raise KeyError("Missing GROQ_API_KEY")
except Exception:
    st.error("‚ùå L·ªói: Ch∆∞a c·∫•u h√¨nh GROQ_API_KEY")
    st.stop()

client = Groq(api_key=api_key)

# --- H√ÄM LOAD DATA ---
def load_data():
    if not os.path.exists(PDF_DIR):
        os.makedirs(PDF_DIR)
        return None
    
    pdf_files = glob.glob(os.path.join(PDF_DIR, "*.pdf"))
    if not pdf_files:
        return None

    documents = []
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)

    progress_text = "ƒêang n·∫°p d·ªØ li·ªáu chi ti·∫øt (pdfplumber)..."
    my_bar = st.progress(0, text=progress_text)
    
    total_files = len(pdf_files)
    for idx, pdf_path in enumerate(pdf_files):
        file_name = os.path.basename(pdf_path)
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for i, page in enumerate(pdf.pages):
                    text = page.extract_text()
                    if text:
                        text = text.replace('\n', ' ').strip()
                        chunks = text_splitter.split_text(text)
                        for chunk in chunks:
                            documents.append(Document(page_content=chunk, metadata={"source": file_name, "page": i + 1}))
        except Exception as e:
            print(f"L·ªói ƒë·ªçc file {file_name}: {e}")
            
        my_bar.progress((idx + 1) / total_files, text=f"ƒêang x·ª≠ l√Ω: {file_name}")

    my_bar.empty()
    
    if not documents: return None
    
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    return FAISS.from_documents(documents, embeddings)

# --- KH·ªûI T·∫†O STATE ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Ch√†o b·∫°n! Chatbot KTC ƒë√£ s·∫µn s√†ng. H√£y h·ªèi v·ªÅ HTML, AI, Python... nh√©!"}]

if "vector_db" not in st.session_state:
    with st.spinner("üîÑ ƒêang kh·ªüi t·∫°o b·ªô n√£o l·∫ßn ƒë·∫ßu..."):
        st.session_state.vector_db = load_data()

# --- SIDEBAR ---
with st.sidebar:
    if os.path.exists(LOGO_PATH):
        st.image(LOGO_PATH, use_container_width=True)
    
    st.markdown("<h3 style='text-align: center; color: #0f4c81;'>TR·ª¢ L√ù KTC</h3>", unsafe_allow_html=True)
    
    if st.session_state.vector_db:
        num_vectors = st.session_state.vector_db.index.ntotal
        st.success(f"üü¢ ƒê√£ h·ªçc: {num_vectors} ƒëo·∫°n ki·∫øn th·ª©c")
    else:
        st.error("üî¥ Ch∆∞a c√≥ d·ªØ li·ªáu")

    st.markdown("---")
    
    if st.button("üîÑ N·∫°p l·∫°i d·ªØ li·ªáu g·ªëc (Force Reload)", use_container_width=True):
        st.session_state.vector_db = None 
        st.rerun() 
        
    if st.button("üßπ L√†m m·ªõi h·ªôi tho·∫°i", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    with st.expander("üïµÔ∏è Soi d·ªØ li·ªáu (Debug)"):
        st.write("D√°n c√¢u h·ªèi v√†o ƒë√¢y ƒë·ªÉ xem m√°y t√¨m th·∫•y ƒëo·∫°n n√†o:")
        debug_query = st.text_input("C√¢u h·ªèi test", "HTML l√† g√¨")
        if st.button("Ki·ªÉm tra t√¨m ki·∫øm") and st.session_state.vector_db:
            docs = st.session_state.vector_db.similarity_search_with_score(debug_query, k=4)
            for doc, score in docs:
                score_color = "green" if score < 1.5 else "red"
                st.markdown(f"**Score:** :{score_color}[{score:.3f}]")
                st.info(doc.page_content)
                st.write("---")

    st.markdown("<div style='margin-top: 20px; font-size: 0.8rem; color: grey'>S·∫£n ph·∫©m KHKT - THCS & THPT Ph·∫°m Ki·ªát</div>", unsafe_allow_html=True)

# --- GIAO DI·ªÜN CH√çNH ---
col1, col2, col3 = st.columns([1, 8, 1])

with col2:
    st.markdown('<h1 class="gradient-text">CHATBOT H·ªñ TR·ª¢ H·ªåC T·∫¨P KTC</h1>', unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; color: #64748b; font-style: italic;'>üöÄ H·ªèi ƒë√°p th√¥ng minh d·ª±a tr√™n t√†i li·ªáu Tin h·ªçc (Anh/Vi·ªát)</p>", unsafe_allow_html=True)
    
    for message in st.session_state.messages:
        avatar = "üßë‚Äçüéì" if message["role"] == "user" else "ü§ñ"
        with st.chat_message(message["role"], avatar=avatar):
            st.markdown(message["content"], unsafe_allow_html=True)

    prompt = st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n t·∫°i ƒë√¢y...")

    if prompt:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="üßë‚Äçüéì"):
            st.markdown(prompt)

        context_text = ""
        relevant_docs = []

        if st.session_state.vector_db:
            results_with_score = st.session_state.vector_db.similarity_search_with_score(prompt, k=TOP_K_RETRIEVAL)
            for doc, score in results_with_score:
                if score < SIMILARITY_THRESHOLD: 
                    context_text += f"\n---\n[Ngu·ªìn: {doc.metadata['source']} - Tr.{doc.metadata['page']}]\nN·ªôi dung: {doc.page_content}"
                    relevant_docs.append(doc)
        
        if not context_text:
            system_instruction = """
            B·∫°n l√† Chatbot KTC.
            Hi·ªán t·∫°i b·∫°n KH√îNG t√¨m th·∫•y th√¥ng tin n√†y trong t√†i li·ªáu PDF ƒë∆∞·ª£c cung c·∫•p.
            TUY NHI√äN, h√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n ki·∫øn th·ª©c chung c·ªßa b·∫°n v·ªÅ Tin h·ªçc.
            B·∫ÆT BU·ªòC: B·∫Øt ƒë·∫ßu c√¢u tr·∫£ l·ªùi b·∫±ng d√≤ng ch·ªØ in nghi√™ng: *"‚ö†Ô∏è N·ªôi dung n√†y ch∆∞a t√¨m th·∫•y c·ª• th·ªÉ trong t√†i li·ªáu t·∫£i l√™n, ƒë√¢y l√† c√¢u tr·∫£ l·ªùi tham kh·∫£o:"*
            """
        else:
            system_instruction = f"""
            B·∫°n l√† tr·ª£ l√Ω Tin h·ªçc KTC. D·ª±a v√†o B·ªêI C·∫¢NH sau ƒë·ªÉ tr·∫£ l·ªùi h·ªçc sinh.
            B·ªêI C·∫¢NH:
            {context_text}
            
            Y√äU C·∫¶U:
            1. Tr·∫£ l·ªùi ch√≠nh x√°c d·ª±a tr√™n b·ªëi c·∫£nh.
            2. Tr√¨nh b√†y ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu.
            """

        with st.chat_message("assistant", avatar="ü§ñ"):
            placeholder = st.empty()
            full_response = ""
            try:
                chat_completion = client.chat.completions.create(
                    messages=[
                        {"role": "system", "content": system_instruction},
                        {"role": "user", "content": prompt}
                    ],
                    model=MODEL_NAME, stream=True, temperature=0.3
                )
                for chunk in chat_completion:
                    if chunk.choices[0].delta.content:
                        full_response += chunk.choices[0].delta.content
                        placeholder.markdown(full_response + "‚ñå")
                placeholder.markdown(full_response)
                
                if relevant_docs:
                    with st.expander("üìö Minh ch·ª©ng t·ª´ t√†i li·ªáu (Click ƒë·ªÉ xem)"):
                        for doc in relevant_docs:
                            st.markdown(f"**üìÑ {doc.metadata['source']} - Trang {doc.metadata['page']}**")
                            st.caption(doc.page_content[:300] + "...") 
                            st.divider()
                
                st.session_state.messages.append({"role": "assistant", "content": full_response})
            except Exception as e:
                st.error(f"L·ªói: {e}")

    st.markdown('<div class="footer-note">‚ö†Ô∏è D·ª± √°n KHKT tr∆∞·ªùng THCS & THPT Ph·∫°m Ki·ªát.</div>', unsafe_allow_html=True)